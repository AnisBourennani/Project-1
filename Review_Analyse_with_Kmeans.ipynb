{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données initiales :\n",
      "    rating                                              title  \\\n",
      "0        4                   No white background! It’s clear!   \n",
      "1        5                Awesome!  Great price!  Works well!   \n",
      "2        5                 Worked but took an hour to install   \n",
      "3        4                                             Decent   \n",
      "4        5                                           LOVE IT!   \n",
      "5        5        Works Great with my IPhone 13 & Magna Case!   \n",
      "6        5                       Great item! Easy to install!   \n",
      "7        4                                         Four Stars   \n",
      "8        5  It is a great value & protects the phone from ...   \n",
      "9        5                         Good to have these around!   \n",
      "10       5                                        These work!   \n",
      "11       5                 Finally something I can Hang onto!   \n",
      "12       5                               Great, great, great!   \n",
      "13       5                                       Great value!   \n",
      "14       4                       Great fit and love the color   \n",
      "15       3                                            It's ok   \n",
      "16       2                       Don't try to tighten it up!!   \n",
      "17       5             Does a good job of protecting my phone   \n",
      "18       5               Light, good sound, cheaper than most   \n",
      "19       5                                   Perfect and easy   \n",
      "\n",
      "                                                 text  \\\n",
      "0   I bought this bc I thought it had the nice whi...   \n",
      "1   Perfect. How pissed am I that I recently paid ...   \n",
      "2   Overall very happy with the end result. If you...   \n",
      "3   Lasted about 9 months then the lock button bro...   \n",
      "4   LOVE THIS CASE! Works better than my expensive...   \n",
      "5   This item works great with my IPhone 13 with M...   \n",
      "6   Item came as described! Fast shipping & east t...   \n",
      "7    Stocking stuffers for my boys & they liked them.   \n",
      "8   My son loves his camo case! It is a great valu...   \n",
      "9   These work. It is a little difficult to get th...   \n",
      "10  These really work! I like having one in my bat...   \n",
      "11  These big phones are so hard for me to hang on...   \n",
      "12           Works great, looks great, sticks, great!   \n",
      "13  Some people have given this less favorable rev...   \n",
      "14  Great fit and love the color. Just enough grip...   \n",
      "15  It's hard to separate the ring from the inner ...   \n",
      "16  Putting it on a night stand drawer or top of h...   \n",
      "17             We've survived a few drops. Nice case.   \n",
      "18  I got these for my wife and she loves them. Th...   \n",
      "19  Went on perfect. Clean phone with wet wipe, th...   \n",
      "\n",
      "                                               images        asin parent_asin  \\\n",
      "0   [{'small_image_url': 'https://images-na.ssl-im...  B08L6L3X1S  B08L6L3X1S   \n",
      "1                                                  []  B079BPGF6C  B079BPGF6C   \n",
      "2   [{'small_image_url': 'https://m.media-amazon.c...  B088DR7Z5B  B0BBGGC8F2   \n",
      "3   [{'small_image_url': 'https://images-na.ssl-im...  B07XRDHDNQ  B07XRDHDNQ   \n",
      "4                                                  []  B00A8ZDL9Y  B00A8ZDL9Y   \n",
      "5                                                  []  B09KH3Z9MF  B0BX2GG16C   \n",
      "6                                                  []  B09DCSNDT3  B09DCT39P2   \n",
      "7                                                  []  B00UKXP6Y2  B07CKPPSB4   \n",
      "8                                                  []  B00W3C3ISY  B00W3C3ISY   \n",
      "9                                                  []  B07NPMQPS9  B07NPMQPS9   \n",
      "10                                                 []  B07MV4KV8S  B09TSCZWX5   \n",
      "11                                                 []  B01JTI3VIG  B01JTI3VIG   \n",
      "12                                                 []  B01MZIG15J  B06VXYPWMC   \n",
      "13                                                 []  B01JTI2K3S  B08FLGTLBQ   \n",
      "14                                                 []  B01LVXS6C0  B01LVXS6C0   \n",
      "15                                                 []  B0719X5WJ5  B0719X5WJ5   \n",
      "16                                                 []  B07KJH11VV  B07KJH11VV   \n",
      "17                                                 []  B0746YX7J7  B0746YX7J7   \n",
      "18                                                 []  B086WK9QH7  B0C5XPBMHM   \n",
      "19                                                 []  B00UH8KUMS  B00UH8KUMS   \n",
      "\n",
      "                         user_id               timestamp  helpful_vote  \\\n",
      "0   AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2021-01-30 22:07:31.196             0   \n",
      "1   AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2018-08-16 18:18:37.349             2   \n",
      "2   AGCI7FAH4GL5FI65HYLKWTMFZ2CQ 2021-08-17 21:21:44.798             3   \n",
      "3   AGCI7FAH4GL5FI65HYLKWTMFZ2CQ 2020-05-26 05:14:42.910             0   \n",
      "4   AGCI7FAH4GL5FI65HYLKWTMFZ2CQ 2014-08-25 19:23:08.000             0   \n",
      "5   AGXVBIUFLFGMVLATYXHJYL4A5Q7Q 2022-03-08 15:32:53.910             0   \n",
      "6   AGXVBIUFLFGMVLATYXHJYL4A5Q7Q 2022-02-15 13:41:53.079             0   \n",
      "7   AGXVBIUFLFGMVLATYXHJYL4A5Q7Q 2017-01-31 13:45:36.000             0   \n",
      "8   AGXVBIUFLFGMVLATYXHJYL4A5Q7Q 2016-04-22 13:20:11.000             0   \n",
      "9   AGKHLEW2SOWHNMFQIJGBECAF7INQ 2019-05-13 14:21:51.964             0   \n",
      "10  AGKHLEW2SOWHNMFQIJGBECAF7INQ 2019-05-13 14:17:40.457             1   \n",
      "11  AGKHLEW2SOWHNMFQIJGBECAF7INQ 2019-05-13 14:14:43.381             0   \n",
      "12  AGKHLEW2SOWHNMFQIJGBECAF7INQ 2018-06-29 00:25:02.311             0   \n",
      "13  AGKHLEW2SOWHNMFQIJGBECAF7INQ 2018-06-29 00:22:33.869             0   \n",
      "14  AGKHLEW2SOWHNMFQIJGBECAF7INQ 2018-02-22 16:28:18.712             0   \n",
      "15  AGKHLEW2SOWHNMFQIJGBECAF7INQ 2017-09-08 00:23:28.331             0   \n",
      "16  AFE337D2J37YRU5U6MVTVKNDKWDA 2020-12-01 00:07:46.760             0   \n",
      "17  AGBFYI2DDIKXC5Y4FARTYDTQBMFQ 2018-10-23 19:50:37.308             0   \n",
      "18  AFTC6ZR5IKNRDG5JCPVNVMU3XV2Q 2020-09-03 18:43:24.740             0   \n",
      "19  AFTC6ZR5IKNRDG5JCPVNVMU3XV2Q 2015-06-18 20:42:10.000             0   \n",
      "\n",
      "    verified_purchase  \n",
      "0                True  \n",
      "1                True  \n",
      "2                True  \n",
      "3                True  \n",
      "4                True  \n",
      "5                True  \n",
      "6                True  \n",
      "7                True  \n",
      "8                True  \n",
      "9                True  \n",
      "10               True  \n",
      "11               True  \n",
      "12               True  \n",
      "13               True  \n",
      "14               True  \n",
      "15               True  \n",
      "16               True  \n",
      "17               True  \n",
      "18               True  \n",
      "19               True  \n"
     ]
    }
   ],
   "source": [
    "# Charger les données\n",
    "df = pd.read_json('reviews.jsonl', lines=True)\n",
    "print(\"Aperçu des données initiales :\")\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Données avec champs sélectionnés :\n",
      "   rating                                title  \\\n",
      "0       4     No white background! It’s clear!   \n",
      "1       5  Awesome!  Great price!  Works well!   \n",
      "2       5   Worked but took an hour to install   \n",
      "3       4                               Decent   \n",
      "4       5                             LOVE IT!   \n",
      "\n",
      "                                                text  \n",
      "0  I bought this bc I thought it had the nice whi...  \n",
      "1  Perfect. How pissed am I that I recently paid ...  \n",
      "2  Overall very happy with the end result. If you...  \n",
      "3  Lasted about 9 months then the lock button bro...  \n",
      "4  LOVE THIS CASE! Works better than my expensive...  \n"
     ]
    }
   ],
   "source": [
    "# Sélection des champs pertinents\n",
    "df = df[['rating', 'title', 'text']]\n",
    "print(\"\\nDonnées avec champs sélectionnés :\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de prétraitement\n",
    "def preprocess_text_spacy(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if (\n",
    "            not token.is_stop  # Exclure les stop words\n",
    "            and token.is_alpha  # Exclure les symboles et chiffres\n",
    "            and len(token) > 2  # Exclure les mots courts\n",
    "        ):\n",
    "            tokens.append(token.lemma_)  # Lemmatisation\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Données après prétraitement :\n",
      "   rating                                title  \\\n",
      "0       4     No white background! It’s clear!   \n",
      "1       5  Awesome!  Great price!  Works well!   \n",
      "2       5   Worked but took an hour to install   \n",
      "3       4                               Decent   \n",
      "4       5                             LOVE IT!   \n",
      "\n",
      "                                                text  \\\n",
      "0  I bought this bc I thought it had the nice whi...   \n",
      "1  Perfect. How pissed am I that I recently paid ...   \n",
      "2  Overall very happy with the end result. If you...   \n",
      "3  Lasted about 9 months then the lock button bro...   \n",
      "4  LOVE THIS CASE! Works better than my expensive...   \n",
      "\n",
      "                                    processed_tokens  \n",
      "0  [buy, think, nice, white, background, turn, cl...  \n",
      "1  [perfect, pissed, recently, pay, fitbit, cable...  \n",
      "2  [overall, happy, end, result, hate, puzzle, lo...  \n",
      "3  [last, month, lock, button, break, decent, pro...  \n",
      "4     [love, case, work, well, expensive, case, lol]  \n"
     ]
    }
   ],
   "source": [
    "# Appliquer la fonction de prétraitement\n",
    "df['processed_tokens'] = df['text'].apply(preprocess_text_spacy)\n",
    "print(\"\\nDonnées après prétraitement :\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Les données prétraitées ont été sauvegardées dans 'processed_reviews.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les données prétraitées si nécessaire\n",
    "df.to_csv('processed_reviews.csv', index=False)\n",
    "print(\"\\nLes données prétraitées ont été sauvegardées dans 'processed_reviews.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Étape 2 : Génération des embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de documents : 1000\n"
     ]
    }
   ],
   "source": [
    "# Charger les données prétraitées\n",
    "df = pd.read_csv('processed_reviews.csv')\n",
    "documents = df['processed_tokens'].apply(eval)  # Convertir les chaînes de tokens en listes Python\n",
    "documents = [\" \".join(tokens) for tokens in documents]  # Convertir les listes en chaînes\n",
    "print(f\"Nombre de documents : {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de la matrice TF-IDF : (1000, 2592)\n",
      "Exemple d'embedding TF-IDF :\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#2. Génération des embeddings \n",
    "#Option  : Utiliser TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Configurer et appliquer TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiter à 5000 caractéristiques\n",
    "tfidf_embeddings = tfidf_vectorizer.fit_transform(documents)\n",
    "print(f\"Taille de la matrice TF-IDF : {tfidf_embeddings.shape}\")\n",
    "print(\"Exemple d'embedding TF-IDF :\")\n",
    "print(tfidf_embeddings.toarray()[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 2 : Utiliser SentenceTransformers (all-MiniLM-L6-v2)\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Charger le modèle SentenceTransformers\n",
    "#model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Générer les embeddings pour chaque document\n",
    "#embeddings = model.encode(documents, show_progress_bar=True)\n",
    "#print(f\"Taille des embeddings : {embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de clusters identifiés : 8\n"
     ]
    }
   ],
   "source": [
    "# 3. Clustering\n",
    "#Option : DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Appliquer DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5, metric='cosine')  # 'cosine' est recommandé pour les données textuelles\n",
    "dbscan_labels = dbscan.fit_predict(tfidf_embeddings)\n",
    "\n",
    "# Nombre de clusters identifiés (ignorer le bruit, label = -1)\n",
    "num_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "print(f\"Nombre de clusters identifiés : {num_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster -1 :\n",
      "Mots-clés les plus fréquents : [('phone', np.int64(726)), ('case', np.int64(551)), ('work', np.int64(246)), ('like', np.int64(215)), ('great', np.int64(212)), ('charge', np.int64(196)), ('fit', np.int64(193)), ('good', np.int64(188)), ('use', np.int64(172)), ('love', np.int64(167)), ('screen', np.int64(152)), ('easy', np.int64(151)), ('look', np.int64(145)), ('time', np.int64(133)), ('need', np.int64(117)), ('get', np.int64(115)), ('cover', np.int64(109)), ('nice', np.int64(106)), ('iphone', np.int64(104)), ('new', np.int64(97))]\n",
      "\n",
      "Cluster 0 :\n",
      "Mots-clés les plus fréquents : [('great', np.int64(43)), ('work', np.int64(30)), ('love', np.int64(29)), ('good', np.int64(27)), ('case', np.int64(23)), ('fit', np.int64(14)), ('car', np.int64(13)), ('phone', np.int64(13)), ('quality', np.int64(13)), ('perfect', np.int64(9)), ('look', np.int64(8)), ('nice', np.int64(8)), ('price', np.int64(8)), ('color', np.int64(6)), ('durable', np.int64(6)), ('product', np.int64(6)), ('feel', np.int64(5)), ('husband', np.int64(5)), ('expect', np.int64(4)), ('like', np.int64(4))]\n",
      "\n",
      "Cluster 2 :\n",
      "Mots-clés les plus fréquents : [('wrong', np.int64(6)), ('phone', np.int64(3)), ('size', np.int64(3)), ('arrive', np.int64(1)), ('break', np.int64(1)), ('cable', np.int64(1)), ('case', np.int64(1)), ('clearly', np.int64(1)), ('fit', np.int64(1)), ('nice', np.int64(1)), ('order', np.int64(1)), ('recommend', np.int64(1)), ('say', np.int64(1)), ('use', np.int64(1))]\n",
      "\n",
      "Cluster 4 :\n",
      "Mots-clés les plus fréquents : [('return', np.int64(6)), ('case', np.int64(2)), ('bouncy', np.int64(1)), ('fast', np.int64(1)), ('fit', np.int64(1)), ('money', np.int64(1)), ('pretty', np.int64(1)), ('problem', np.int64(1)), ('product', np.int64(1)), ('small', np.int64(1)), ('smart', np.int64(1)), ('watch', np.int64(1)), ('work', np.int64(1))]\n",
      "\n",
      "Cluster 3 :\n",
      "Mots-clés les plus fréquents : [('great', np.int64(4)), ('value', np.int64(4)), ('phone', np.int64(3)), ('case', np.int64(2)), ('charge', np.int64(1)), ('design', np.int64(1)), ('durable', np.int64(1)), ('exactly', np.int64(1)), ('fit', np.int64(1)), ('good', np.int64(1)), ('light', np.int64(1)), ('love', np.int64(1)), ('money', np.int64(1)), ('otterbox', np.int64(1)), ('price', np.int64(1)), ('sturdy', np.int64(1))]\n",
      "\n",
      "Cluster 1 :\n",
      "Mots-clés les plus fréquents : [('review', np.int64(59)), ('like', np.int64(22)), ('long', np.int64(21)), ('time', np.int64(21)), ('update', np.int64(21)), ('experience', np.int64(20)), ('info', np.int64(20)), ('rank', np.int64(20)), ('reviewer', np.int64(20)), ('different', np.int64(13)), ('item', np.int64(11)), ('new', np.int64(11)), ('receive', np.int64(11)), ('say', np.int64(11)), ('useful', np.int64(11)), ('accept', np.int64(10)), ('help', np.int64(10)), ('hesitate', np.int64(10)), ('little', np.int64(10)), ('notice', np.int64(10))]\n",
      "\n",
      "Cluster 7 :\n",
      "Mots-clés les plus fréquents : [('protect', np.int64(9)), ('screen', np.int64(5)), ('case', np.int64(4)), ('fit', np.int64(2)), ('phone', np.int64(2)), ('average', np.int64(1)), ('box', np.int64(1)), ('bulky', np.int64(1)), ('camera', np.int64(1)), ('completely', np.int64(1)), ('difficult', np.int64(1)), ('drop', np.int64(1)), ('exactly', np.int64(1)), ('expensive', np.int64(1)), ('fall', np.int64(1)), ('feel', np.int64(1)), ('hand', np.int64(1)), ('hard', np.int64(1)), ('high', np.int64(1)), ('iphone', np.int64(1))]\n",
      "\n",
      "Cluster 6 :\n",
      "Mots-clés les plus fréquents : [('screen', np.int64(24)), ('protector', np.int64(14)), ('phone', np.int64(11)), ('crack', np.int64(8)), ('daughter', np.int64(7)), ('good', np.int64(5)), ('iphone', np.int64(5)), ('receive', np.int64(5)), ('bubble', np.int64(3)), ('case', np.int64(3)), ('free', np.int64(3)), ('little', np.int64(3)), ('one', np.int64(3)), ('opinion', np.int64(3)), ('purpose', np.int64(3)), ('review', np.int64(3)), ('thought', np.int64(3)), ('time', np.int64(3)), ('touch', np.int64(3)), ('try', np.int64(3))]\n",
      "\n",
      "Cluster 5 :\n",
      "Mots-clés les plus fréquents : [('case', np.int64(8)), ('iphone', np.int64(7)), ('button', np.int64(6)), ('fit', np.int64(6)), ('good', np.int64(6)), ('offer', np.int64(6)), ('phone', np.int64(6)), ('protection', np.int64(6)), ('adequate', np.int64(5)), ('daughter', np.int64(5)), ('interfere', np.int64(5)), ('far', np.int64(2)), ('otterbox', np.int64(2)), ('screen', np.int64(2)), ('color', np.int64(1)), ('control', np.int64(1)), ('effort', np.int64(1)), ('fairly', np.int64(1)), ('feel', np.int64(1)), ('find', np.int64(1))]\n"
     ]
    }
   ],
   "source": [
    "#4. Analyse des clusters : \n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Associer les documents à leurs clusters\n",
    "clusters = defaultdict(list)\n",
    "for i, label in enumerate(dbscan_labels):\n",
    "    clusters[label].append(documents[i])\n",
    "\n",
    "# Analyser les mots-clés dans chaque cluster\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "for cluster_id, docs in clusters.items():\n",
    "    print(f\"\\nCluster {cluster_id} :\")\n",
    "    vectorizer = CountVectorizer(max_features=20)  # Limiter à 10 mots-clés\n",
    "    word_counts = vectorizer.fit_transform(docs)\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    freqs = word_counts.sum(axis=0).A1\n",
    "    keywords = sorted(zip(words, freqs), key=lambda x: -x[1])\n",
    "    print(\"Mots-clés les plus fréquents :\", keywords)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
